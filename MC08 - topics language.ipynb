{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media Cloud: Topics: Measuring Language\n",
    "=======================================\n",
    "\n",
    "At this point you have a topic created in Media Cloud - a corpus of open-news web content related to an issue you want to investigate, discovered on mulitple platforms across the internet. The topic lets you analyze language in a variety of ways.\n",
    "\n",
    "Our API lets exposes a few key endpoints for analyzing language within a topic:\n",
    "* `topicWordCount`:  list the top words in stories that match your query in the topic (read the [low level docs](https://github.com/berkmancenter/mediacloud/blob/master/doc/api_2_0_spec/topics_api_2_0_spec.md#wclist))\n",
    "* `topicSnapshotWord2VecModel`: return an `application/octext-stream` trained word2vec model file ([low level docs](https://github.com/berkmancenter/mediacloud/blob/master/doc/api_2_0_spec/topics_api_2_0_spec.md#snapshotssnapshots_idword2vec_modelmodels_id-get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a Connection and Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab your API key from the environment variable and create a client for talking to Media Cloud\n",
    "import os, mediacloud.api\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import JSON\n",
    "load_dotenv()  # load config from .env file\n",
    "mc = mediacloud.api.MediaCloud(os.getenv('MC_API_KEY'))\n",
    "mediacloud.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this topic for the explanantion\n",
    "SOURDOUGH_TOPIC = 4138\n",
    "# find the latest snapshot\n",
    "snapshots = mc.topicSnapshotList(SOURDOUGH_TOPIC)\n",
    "latest_snapshot_id = snapshots[0]['snapshots_id'] # grab the id of the latest snapshot\n",
    "# pull out the automatically-generated monthly timespans, and the overall one\n",
    "timespans = mc.topicTimespanList(SOURDOUGH_TOPIC)\n",
    "overall_timespan = [t for t in timespans if t['period'] == 'overall'][0]\n",
    "monthly_timespans = [t for t in timespans if t['period'] == 'monthly']\n",
    "# grab a subtopic to work with as well\n",
    "focal_sets = mc.topicFocalSetList(SOURDOUGH_TOPIC)\n",
    "reddit_foci_id = focal_sets[0]['foci'][0]['foci_id']\n",
    "# and some timespans in the reddit subtopic\n",
    "reddit_timespans = mc.topicTimespanList(SOURDOUGH_TOPIC, foci_id=reddit_foci_id)\n",
    "reddit_overall_timespan = [t for t in reddit_timespans if t['period'] == 'overall'][0]\n",
    "reddit_monthly_timespans = [t for t in reddit_timespans if t['period'] == 'monthly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Words\n",
    "\n",
    "Like any regular query, you can do simple word counts within your topic to look at language used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze top words by month\n",
    "import dateparser\n",
    "monthly_top_words = []\n",
    "for t in monthly_timespans:\n",
    "    month_top_words = mc.topicWordCount(SOURDOUGH_TOPIC, timespans_id=t['timespans_id'])\n",
    "    monthly_top_words.append({\n",
    "        'timespans_id': t['timespans_id'],\n",
    "        'start_date': dateparser.parse(t['start_date']),\n",
    "        'end_date': dateparser.parse(t['end_date']),\n",
    "        'top_words': month_top_words\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in monthly_top_words:\n",
    "    print('{}: {}'.format(m['start_date'],', '.join([m['term'] for m in m['top_words'][:10]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Note that for every `snapshot` we train a word2vec model on the corpus. You can download and use that model to support more complicated computational language analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the model trained on the entire corpus\n",
    "snapshots = mc.topicSnapshotList(SOURDOUGH_TOPIC)\n",
    "latest_snapshot = snapshots[0]\n",
    "model_info = latest_snapshot['word2vec_models'][0]\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model locally\n",
    "raw_model = mc.topicSnapshotWord2VecModel(SOURDOUGH_TOPIC, latest_snapshot_id, model_info['models_id'])\n",
    "path_to_model = \"topic-word2vec-{}.model\".format(model_info['models_id'])\n",
    "model_byte_array = bytes(raw_model)\n",
    "cache_file = open(path_to_model, 'w+b')\n",
    "cache_file.write(model_byte_array)\n",
    "cache_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "import gensim\n",
    "model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(path_to_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the full embedding for a word\n",
    "model['yeast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similar words in the space\n",
    "model.most_similar('yeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
