{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media Cloud: Topics: Measuring Attention\n",
    "========================================\n",
    "\n",
    "At this point you have a topic created in Media Cloud - a corpus of open-news web content related to an issue you want to investigate, discovered on mulitple platforms across the internet.\n",
    "\n",
    "Our API lets exposes one key endpoint for analyzing attention within a topic:\n",
    "* `topicStoryCount`: return the total number of stories in the topic matching your query, or return that as a time series (read [the low level documentation](https://github.com/berkmancenter/mediacloud/blob/master/doc/api_2_0_spec/topics_api_2_0_spec.md#storiescount) for more details about the parameters it supports)\n",
    "* `topicStoryList`:  page through the actual stories that match your query in the topic (read the [low level docs](https://github.com/berkmancenter/mediacloud/blob/master/doc/api_2_0_spec/topics_api_2_0_spec.md#storieslist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a Connection and Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab your API key from the environment variable and create a client for talking to Media Cloud\n",
    "import os, mediacloud.api\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import JSON\n",
    "load_dotenv()  # load config from .env file\n",
    "mc = mediacloud.api.MediaCloud(os.getenv('MC_API_KEY'))\n",
    "mediacloud.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this topic for the explanantion\n",
    "SOURDOUGH_TOPIC = 4138\n",
    "# find the latest snapshot\n",
    "snapshots = mc.topicSnapshotList(SOURDOUGH_TOPIC)\n",
    "latest_snapshot_id = snapshots[0]['snapshots_id'] # grab the id of the latest snapshot\n",
    "# pull out the automatically-generated monthly timespans, and the overall one\n",
    "timespans = mc.topicTimespanList(SOURDOUGH_TOPIC)\n",
    "overall_timespan = [t for t in timespans if t['period'] == 'overall'][0]\n",
    "monthly_timespans = [t for t in timespans if t['period'] == 'monthly']\n",
    "# grab a subtopic to work with as well\n",
    "focal_sets = mc.topicFocalSetList(SOURDOUGH_TOPIC)\n",
    "reddit_foci_id = focal_sets[0]['foci'][0]['foci_id']\n",
    "# and some timespans in the reddit subtopic\n",
    "reddit_timespans = mc.topicTimespanList(SOURDOUGH_TOPIC, foci_id=reddit_foci_id)\n",
    "reddit_overall_timespan = [t for t in reddit_timespans if t['period'] == 'overall'][0]\n",
    "reddit_monthly_timespans = [t for t in reddit_timespans if t['period'] == 'monthly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Total Attention\n",
    "\n",
    "Let's start by looking at the total corpus size, and seeing how many stories of that corpus were discovered via someone sharing them on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stories = mc.topicStoryCount(SOURDOUGH_TOPIC, timespans_id=overall_timespan['timespans_id'])\n",
    "total_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_from_reddit = mc.topicStoryCount(SOURDOUGH_TOPIC, timespans_id=reddit_overall_timespan['timespans_id'])\n",
    "stories_from_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = stories_from_reddit['count'] / total_stories['count']\n",
    "'{:.2%} of our corpus was discovered from someone sharing it on Reddit'.format(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Attention over Time\n",
    "\n",
    "You can measure attention over time by using the `split` parameter with you call to `topicStoryList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which stories were most shared on Reddit\n",
    "results = mc.topicStoryCount(SOURDOUGH_TOPIC, timespans_id=overall_timespan['timespans_id'], split=True, split_period='month')\n",
    "JSON(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably notice that many of these stories are outside of our topics start/end dates. Date guessing on the open web is hard (we [wrote our own `date_guesser` package](https://github.com/mitmedialab/date_guesser) to do it). **We get around 10% of our dates wrong**, sometimes in stupid ways. In addition, some content isn't dateable at all - wikipedia pages for instance. So you probably want to filter results like these by thier dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Stories\n",
    "\n",
    "Of course you probably want to know *which* stories are in your topic. `topicStoryList` helps with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which stories were most shared on Reddit\n",
    "# Note the use of \"post_count\" here to sort by total number of posts (within the corpus)\n",
    "top_stories_from_reddit = mc.topicStoryList(SOURDOUGH_TOPIC, timespans_id=reddit_overall_timespan['timespans_id'], sort='post_count')\n",
    "JSON(top_stories_from_reddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, what you probably want to do is list all these stories. You can use the 'link_id' result for paging, as describing in our [docs on paging through topic API endpoint results](https://github.com/berkmancenter/mediacloud/blob/master/doc/api_2_0_spec/topics_api_2_0_spec.md#paging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_topic_matching_stories(mc_client, topics_id, snapshots_id=None, foci_id=None, timespans_id=None, q=None):\n",
    "    \"\"\"\n",
    "    Return all the stories matching a query within your Media Cloud topic. Page through the results automatically.\n",
    "    :param mc_client: a `mediacloud.api.MediaCloud` object instantiated with your API key already\n",
    "    :param topics_id: the id of the topic you are using\n",
    "    :param snapshots_id: the snapshot (\"version\") you want to search within\n",
    "    :param foci_id: the focus (\"subtopic\") you want to search within\n",
    "    :param timespans_id: the timespan you want to search within\n",
    "    :param q: a boolean query to filter stories even further\n",
    "    :return: a list of media cloud story items within the topic that match\n",
    "    \"\"\"\n",
    "    link_id = None\n",
    "    more_stories = True\n",
    "    stories = []\n",
    "    while more_stories:\n",
    "        page = mc_client.topicStoryList(topics_id,\n",
    "                                        snapshots_id=snapshots_id, foci_id=foci_id, timespans_id=timespans_id,\n",
    "                                        q=q, link_id=link_id, limit=500)\n",
    "        stories += page['stories']\n",
    "        print(\"  got one page with {} stories\".format(len(page['stories'])))\n",
    "        if 'next' in page['link_ids']:\n",
    "            link_id = page['link_ids']['next']\n",
    "        else:\n",
    "            more_stories = False\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch *all* the stories we discovered on Reddit\n",
    "all_stories_from_reddit = all_topic_matching_stories(mc, SOURDOUGH_TOPIC, timespans_id=reddit_overall_timespan['timespans_id'])\n",
    "JSON(all_stories_from_reddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you probably want to dump this to a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write the CSV\n",
    "import csv\n",
    "fieldnames = ['stories_id', 'publish_date', 'title', 'url', 'language', 'ap_syndicated', 'facebook_share_count', 'media_id', 'media_name', 'media_url']\n",
    "with open('topic-story-list.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    for s in all_stories_from_reddit:\n",
    "        writer.writerow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
